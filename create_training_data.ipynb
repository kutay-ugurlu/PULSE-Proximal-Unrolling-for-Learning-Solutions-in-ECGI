{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tqdm\n",
    "from numpy import ndarray as nd \n",
    "from glob import glob \n",
    "from os.path import join\n",
    "from pymatreader import read_mat\n",
    "from matplotlib import pyplot as plt \n",
    "from utils import *\n",
    "import torch\n",
    "%matplotlib inline\n",
    "\n",
    "# training_data_location = \"D:\\BayesianECGI\\Auckland\\Pig1\\Signals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEOM = read_mat(\"D:\\\\BayesianECGI\\\\Utilities\\\\Geometries\\\\epigeom490corrected.mat\")\n",
    "PTS = GEOM[\"epigeom490corrected\"][\"pts\"]\n",
    "FAC = GEOM[\"epigeom490corrected\"][\"fac\"]\n",
    "A = read_mat(\"D:\\\\BayesianECGI\\\\Utilities\\\\Geometries\\\\ForwMat_HLT.mat\")\n",
    "A = A[\"Trf_HLT_leads\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_location = join(\"D:\\BayesianECGI\\Bayesian\\TrainingData\",\"features\")\n",
    "files = glob(join(training_data_location,\"*.mat\"))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((490,1))\n",
    "Y = np.empty((192,1))\n",
    "AT = np.empty((490,1))\n",
    "intervals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,file in enumerate(files): \n",
    "    data = read_mat(file)\n",
    "    begin = data[\"features\"][\"QRSbegin\"]\n",
    "    end = data[\"features\"][\"QRSend\"]\n",
    "    interval = end-begin \n",
    "    intervals.append(interval)\n",
    "    QRS = data[\"ts\"][\"potvals\"][:,begin:end]\n",
    "    if np.sum(np.logical_or(QRS<-60,QRS>60)):\n",
    "        continue\n",
    "    at = data[\"features\"][\"AT\"] - begin\n",
    "    # assert np.max(at)<=interval, (print(np.max(at), interval) and False) or \"AT out of QRS!\"\n",
    "    X = np.hstack((X,QRS))\n",
    "    AT = np.hstack((AT,np.expand_dims(at,1)))\n",
    "    \n",
    "X = X[:,1:]\n",
    "AT = AT[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,6))\n",
    "plt.plot(X.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,6))\n",
    "plt.plot(X[:,5000:15000].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,6))\n",
    "plt.plot(X[:,0:2000].T);\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There exists 27951 samples, For convenience for the temporal batch_size dependency, I am going to slice it to 8192x3+1024x2 =  26624, and use the validation ratio in two's powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,0:26624]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = A.dot(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.imshow(Y[:,:100],extent=[0,1,0,1]);\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(X[:,:100],extent=[0,1,0,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = [-30,30]\n",
    "plt.figure(figsize=(24,18))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(Y.T);\n",
    "plt.grid()\n",
    "plt.ylim(ylim)\n",
    "Y,N,_ = add_noise(Y,20)\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(N.T);\n",
    "plt.ylim(ylim)\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(Y.T);\n",
    "plt.ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ordering = read_mat('newnode_order_3.mat')['node_order'] - 1 # For MATLAB to Python indexing, there is -1\n",
    "node_ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"heart_concat_new.npy\",X,allow_pickle=True)\n",
    "np.save(\"torso_concat_new.npy\",Y,allow_pickle=True)\n",
    "np.save(\"AT_new.npy\",AT,allow_pickle=True)\n",
    "np.save(\"heart_concat_reordered_new.npy\",X[node_ordering,:],allow_pickle=True)\n",
    "np.save(\"torso_concat_reordered_new.npy\",Y,allow_pickle=True)\n",
    "np.save(\"AT_reordered_new.npy\",AT[node_ordering,:],allow_pickle=True)\n",
    "np.save(\"A_HLT_reordered.npy\",A[:,node_ordering],allow_pickle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\qrs_21jun01_12.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\qrs_21jun01_3.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\qrs_21jun01_4.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\qrs_8oct02_31.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\qrs_8oct02_32.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm131200_13qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0055_qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0056_qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0066_qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0082_qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0086_qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0090_qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0120_qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0123_qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0130_qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0159_qrs.mat',\n",
       " 'D:\\\\BayesianECGI\\\\Bayesian\\\\TestData\\\\EP\\\\rsm8oct02_0163_qrs.mat']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.empty((490,1))\n",
    "Y_test = np.empty((192,1))\n",
    "AT_test = np.empty((490,1))\n",
    "intervals = []\n",
    "test_data_location = join(\"D:\\BayesianECGI\\Bayesian\\TestData\",\"EP\")\n",
    "test_files = glob(join(test_data_location,\"*.mat\"))\n",
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_container = []\n",
    "test_data_counter = np.array([])\n",
    "for i,file in enumerate(test_files):\n",
    "    data_container = {} \n",
    "    data = read_mat(file)\n",
    "    QRS = data[\"ep\"][\"potvals\"]\n",
    "    time_frames = QRS.shape[-1]\n",
    "    test_data_counter = np.hstack((test_data_counter,(np.ones((time_frames,1))*(i)).flatten()))\n",
    "    at = data[\"ep\"][\"at\"]\n",
    "    noise_free_torso = A.dot(QRS)\n",
    "    noisy_torso, N, std_noise = add_noise(noise_free_torso,20)\n",
    "    # assert np.max(at)<=interval, (print(np.max(at), interval) and False) or \"AT out of QRS!\"\n",
    "    X_test = np.hstack((X_test,QRS))\n",
    "    AT_test = np.hstack((AT_test,np.expand_dims(at,1)))\n",
    "    data_container['x'] = torch.from_numpy(QRS[node_ordering,:])\n",
    "    data_container['y'] = torch.from_numpy(noisy_torso)\n",
    "    data_container['badleads'] = torch.from_numpy(np.where(np.in1d(node_ordering,data['ep']['badleads']-1))[0]) # -1 Due to MATLAB ordering\n",
    "    data_container['std_n'] = std_noise\n",
    "    data_container['at'] = at[node_ordering]\n",
    "    data_container['paceloc'] = torch.from_numpy(np.where(np.in1d(node_ordering,data['ep']['pacing']-1))[0]) \n",
    "    test_data_container.append(data_container)    \n",
    "X_test = X_test[:,1:]\n",
    "AT_test = AT_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = A.dot(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item['x'].shape[1] for item in test_data_container]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylim = [-15,15]\n",
    "plt.figure(figsize=(24,18))\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(X_test.T);\n",
    "plt.grid()\n",
    "Y_test_noisy,N,_ = add_noise(Y_test,20)\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(N.T);\n",
    "plt.ylim(ylim)\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(Y_test.T);\n",
    "plt.ylim(ylim)\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(Y_test_noisy.T);\n",
    "plt.ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"test_heart_concat.npy\",X_test,allow_pickle=True)\n",
    "np.save(\"test_torso_concat.npy\",Y_test,allow_pickle=True)\n",
    "np.save(\"test_AT.npy\",AT_test,allow_pickle=True)\n",
    "np.save(\"test_heart_concat_reordered.npy\",X_test[node_ordering,:],allow_pickle=True)\n",
    "np.save(\"test_torso_concat_reordered.npy\",Y_test,allow_pickle=True)\n",
    "np.save(\"test_AT_reordered.npy\",AT_test[node_ordering,:],allow_pickle=True)\n",
    "np.save(\"test_data_counter.npy\",test_data_counter,allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_data_container,'test_dictionary.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DFBlock\n",
    "import torch\n",
    "x_hat = DFBlock(torch.from_numpy(A), torch.Tensor([1.75e-8]), torch.from_numpy(Y), torch.zeros_like(torch.from_numpy(X)), 'cpu', 1)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.imshow(X[:,:100],extent=[0,1,0,1]);\n",
    "plt.title('Ground-truth')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(x_hat[:,:100].numpy(),extent=[0,1,0,1]);\n",
    "plt.title('Tikhonov solution')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlecgi_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a67d8469e8f62705ca77999b08c5463267b6f6cc81e6290613603763a8460c2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
